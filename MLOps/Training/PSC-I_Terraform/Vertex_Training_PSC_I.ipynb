{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Training using Private Service Connect interface\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/jbrache/vertex-ai-things/blob/main/MLOps/Training/Vertex_Training_PSC_I.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fjbrache%2Fvertex-ai-things%2Fmain%2FMLOps%2FTraining%2FVertex_Training_PSC_I.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/jbrache/vertex-ai-things/blob/main/MLOps/Training/Vertex_Training_PSC_I.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/jbrache/vertex-ai-things/blob/main/MLOps/Training/Vertex_Training_PSC_I.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu4do1bcet6m"
      },
      "source": [
        "| Author(s) |\n",
        "| --- |\n",
        "| [Jose Brache](https://github.com/jbrache) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Private Service Connect interface is recommended for private connectivity since it reduces the chance of IP exhaustion and allows for transitive peering. See [Set up a Private Service Connect interface](https://cloud.google.com/vertex-ai/docs/general/vpc-psc-i-setup) on how to configure it for Vertex AI.\n",
        "\n",
        "Review the public docs for the latest information on support: [Schedule training jobs based on resource availability](https://cloud.google.com/vertex-ai/docs/training/psc-i-egress)\n",
        "\n",
        "This example covers the following steps:\n",
        "1. Setup projects as the **VPC Host Project (Project 'a')** and the **Vertex AI Service Project (Project 'b')**\n",
        "2. Create Test Training Code Container\n",
        "3. Build/Push Custom Docker Container using Cloud Build\n",
        "4. Use previously setup (from terrform) PSC-I network attachment in VPC Host Project for Vertex AI Training in **us-central1** or **us-west1**\n",
        "6. Prepare Training Job\n",
        "7. Submit Training Job with PSC-I in **us-central1**\n",
        "8. Submit Training Job with PSC-I in **us-west1**\n",
        "7. Clean Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVUK0GRWL4kn"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8LkGgxBe55P"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tghR70frqiS"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "\n",
        "# if \"google.colab\" in sys.modules:\n",
        "#     !pip3 install --upgrade google-cloud-aiplatform\n",
        "\n",
        "#     # Restart the notebook kernel after installs.\n",
        "#     import IPython\n",
        "\n",
        "#     app = IPython.Application.instance()\n",
        "#     app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfZUIrKLtXBU"
      },
      "source": [
        "---\n",
        "\n",
        "#### ⚠️ Do not forget to click the \"RESTART RUNTIME\" button above.\n",
        "\n",
        "---\n",
        "\n",
        "If you install additional packages, it's suggested to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMuTPovBfCuP"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbAYymZP8VQJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bte0-njbsj1e"
      },
      "source": [
        "# 0-0. Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
            "\n",
            "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
            "INFORMATION: Project 'ds-dev-jb0001' has no 'environment' tag set. Use either 'Production', 'Development', 'Test', or 'Staging'. Add an 'environment' tag using `gcloud resource-manager tags bindings create`.\n",
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "############## Set Region for Shared Resources ###########################\n",
        "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
        "# This is the region where the Vertex AI Test Container will be deployed\n",
        "IMAGE_REGION = \"us\"  # @param {type: \"string\"}\n",
        "\n",
        "############## Set VPC Host Project ###########################\n",
        "# Calling this Project 'a' where the VPC Host project exists\n",
        "PROJECT_ID_VPC_HOST = \"jb01-shared-vpc-dev\"  # @param {type:\"string\"}\n",
        "VPC_NAME = \"vertex-vpc-dev\"\n",
        "\n",
        "# Region #1\n",
        "REGION_CENTRAL = \"us-central1\"  # @param {type: \"string\"}\n",
        "SUBNET_NAME_CENTRAL = f\"{REGION_CENTRAL}-vertex-psci\"\n",
        "NETWORK_ATTACHMENT_NAME_CENTRAL = f\"{REGION_CENTRAL}-vertex-psci\"\n",
        "\n",
        "# Region #2\n",
        "REGION_WEST = \"us-west1\"  # @param {type: \"string\"}\n",
        "SUBNET_NAME_WEST = f\"{REGION_WEST}-vertex-psci\"\n",
        "NETWORK_ATTACHMENT_NAME_WEST = f\"{REGION_WEST}-vertex-psci\"\n",
        "\n",
        "############## Set Vertex AI Project ###########################\n",
        "# Calling this Project 'b' where Vertex AI Training jobs run\n",
        "PROJECT_ID = \"ds-dev-jb0001\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW6HcE3T6a5m"
      },
      "source": [
        "## 0-1. Enable APIs\n",
        "The following APIs are enabled in this demo:\n",
        "1. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "2. [Enable the Cloud Build API](https://console.cloud.google.com/flows/enableapi?apiid=cloudbuild.googleapis.com)\n",
        "3. [Enable the Artifact Registry API](https://console.cloud.google.com/flows/enableapi?apiid=artifactregistry.googleapis.com): You must enable the Artifact Registry API for your project. You will store your custom training container in Artifact Registry. [Learn more about Enabling the Artifact Registry service](https://cloud.google.com/artifact-registry/docs/enable-service)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wAi6QffPHYx5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation \"operations/acf.p2-277369590897-4f19a595-79d3-4bb1-b948-ed243c1517fb\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "############# Enable the APIs for Vertex AI Project ########################\n",
        "!gcloud services enable --project=$PROJECT_ID aiplatform.googleapis.com artifactregistry.googleapis.com cloudbuild.googleapis.com --project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0-1. IAM Bindings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_NUMBER = !(gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated IAM policy for project [ds-dev-jb0001].\n",
            "bindings:\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
            "  role: roles/artifactregistry.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:277369590897-compute@developer.gserviceaccount.com\n",
            "  - serviceAccount:277369590897@cloudbuild.gserviceaccount.com\n",
            "  role: roles/cloudbuild.builds.builder\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
            "  role: roles/cloudbuild.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@compute-system.iam.gserviceaccount.com\n",
            "  role: roles/compute.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@containerregistry.iam.gserviceaccount.com\n",
            "  role: roles/containerregistry.ServiceAgent\n",
            "- members:\n",
            "  - serviceAccount:277369590897@cloudservices.gserviceaccount.com\n",
            "  role: roles/editor\n",
            "- members:\n",
            "  - user:jose@jbrache.altostrat.com\n",
            "  role: roles/owner\n",
            "- members:\n",
            "  - serviceAccount:service-277369590897@gcp-sa-pubsub.iam.gserviceaccount.com\n",
            "  role: roles/pubsub.serviceAgent\n",
            "etag: BwZCt0N8e7A=\n",
            "version: 1\n"
          ]
        }
      ],
      "source": [
        "COMPUTE_ENGINE_SERVICE_AGENT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
        "  --member=\"serviceAccount:$COMPUTE_ENGINE_SERVICE_AGENT\"  \\\n",
        "  --role=\"roles/cloudbuild.builds.builder\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "## 0-2. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "## 0-3. Training Code Container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a9lEK0q5zBpX"
      },
      "outputs": [],
      "source": [
        "# Training code container def\n",
        "CONTAINER_DIR = \"test_container\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCjeCcvnuX8s"
      },
      "source": [
        "Verify the location where the training code exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RB711jiblKwo"
      },
      "outputs": [],
      "source": [
        "# Remove if there's any such folder already\n",
        "!rm -rf $CONTAINER_DIR\n",
        "# Create your app directory\n",
        "!mkdir -p $CONTAINER_DIR/trainer\n",
        "# Create a subdirectory for store the training scripts\n",
        "!touch $CONTAINER_DIR/trainer/train.py\n",
        "# Create the init file\n",
        "!touch $CONTAINER_DIR/trainer/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-3XFPHR_zD9U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local container directory with training code: test_container\n",
            "Check whether the container directory exists: True\n"
          ]
        }
      ],
      "source": [
        "# Print the location where the training code exists, will be used to create the artifact registry container\n",
        "print(f\"Local container directory with training code: {CONTAINER_DIR}\")\n",
        "print(\"Check whether the container directory exists:\", os.path.exists(CONTAINER_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zzdREP9KlVk5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting test_container/trainer/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $CONTAINER_DIR/trainer/train.py\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"Parses command-line arguments.\"\"\"\n",
        "  \"\"\"Argument parser.\n",
        "\n",
        "  Returns:\n",
        "    Dictionary of arguments.\n",
        "  \"\"\"\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  parser.add_argument('--log-level', help='Logging level.', choices=['DEBUG', 'ERROR', 'FATAL', 'INFO', 'WARN'], default='INFO')\n",
        "  parser.add_argument('--sleep', help='Amount of time in seconds to sleep.', type=str, default='600s')\n",
        "  parsed, unknown = parser.parse_known_args()\n",
        "  return parsed, unknown\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \"\"\"Entry point\"\"\"\n",
        "  arguments, unknown_args = parse_args()\n",
        "  logging.basicConfig(level=arguments.log_level)\n",
        "\n",
        "  if arguments.sleep[-1] == \"s\":\n",
        "    sleep = int(arguments.sleep[:-1])\n",
        "  else:\n",
        "    sleep = int(arguments.sleep)\n",
        "\n",
        "  # Sleeping 600 seconds to connect the web shell\n",
        "  logging.info(f'Sleeping for {sleep} seconds...')\n",
        "  time.sleep(sleep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uPgYF3aNpCcB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: %%writefile is a cell magic, but the cell body is empty.\n"
          ]
        }
      ],
      "source": [
        "%%writefile $CONTAINER_DIR/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HnEqShsuUoxT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_container/pyproject.toml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $CONTAINER_DIR/pyproject.toml\n",
        "[tool.poetry]\n",
        "package-mode = false\n",
        "\n",
        "[tool.poetry.dependencies]\n",
        "python = \"==3.10.12\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pQRdE718T56-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_container/Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile $CONTAINER_DIR/Dockerfile\n",
        "# https://medium.com/@albertazzir/blazing-fast-python-docker-builds-with-poetry-a78a66f5aed0\n",
        "\n",
        "# Fetch the base image\n",
        "# https://hub.docker.com/r/amd64/python/\n",
        "# FROM amd64/python:3.10.12\n",
        "# The builder image, used to build the virtual environment\n",
        "FROM python:3.10.12-slim-bookworm\n",
        "\n",
        "# Install pipx\n",
        "RUN apt-get update && \\\n",
        "    apt-get install --no-install-suggests --no-install-recommends --yes pipx\n",
        "\n",
        "# Install network tools: ping, dig, nslookup\n",
        "RUN apt-get update && \\\n",
        "    apt-get install -y net-tools iputils-ping tcpdump dnsutils\n",
        "\n",
        "ENV PATH=\"/root/.local/bin:${PATH}\"\n",
        "RUN pipx install poetry\n",
        "RUN pipx inject poetry poetry-plugin-bundle\n",
        "\n",
        "ENV POETRY_NO_INTERACTION=1 \\\n",
        "    POETRY_VIRTUALENVS_IN_PROJECT=1 \\\n",
        "    POETRY_VIRTUALENVS_CREATE=1 \\\n",
        "    POETRY_CACHE_DIR=/tmp/poetry_cache\n",
        "\n",
        "# Set the working dir for the rest of the commands\n",
        "WORKDIR /\n",
        "\n",
        "# COPY requirements.txt .\n",
        "COPY pyproject.toml .\n",
        "# COPY poetry.lock .\n",
        "\n",
        "RUN poetry install --no-root && rm -rf $POETRY_CACHE_DIR\n",
        "\n",
        "ENV VIRTUAL_ENV=/.venv \\\n",
        "    PATH=\"/.venv/bin:$PATH\"\n",
        "\n",
        "# Copies the trainer code to the docker image.\n",
        "COPY trainer /trainer\n",
        "\n",
        "# Sets up the entry point to invoke the trainer.\n",
        "ENTRYPOINT [ \"poetry\", \"run\", \"python\", \"-m\", \"trainer.train\" ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mVUy1rqcKkp"
      },
      "source": [
        "# 1-0. Build and Push Custom Container to Artifact Registry\n",
        "\n",
        "You must have enabled the Artifact Registry API for your project in the previous steps. You will store your custom training container in Artifact Registry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKHSoEOIi6L4"
      },
      "source": [
        "## 1-1. Create a private Docker repository\n",
        "Your first step is to create a Docker repository in Artifact Registry.\n",
        "\n",
        "1 - Run the `gcloud artifacts repositories create` command to create a new Docker repository with your region with the description `Docker repository`.\n",
        "\n",
        "2 - Run the `gcloud artifacts repositories list` command to verify that your repository was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzoZDGHTzFlO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Private Repo: test-training\n",
            "Training Container Image: us-central1-docker.pkg.dev/ds-dev-jb0001/test-training/test:latest\n"
          ]
        }
      ],
      "source": [
        "# Repo to create / use for running training job\n",
        "PRIVATE_REPO = \"vertex-training-test\"\n",
        "TRAIN_IMAGE = (\n",
        "    f\"{IMAGE_REGION}-docker.pkg.dev/{PROJECT_ID}/{PRIVATE_REPO}/test:latest\"\n",
        ")\n",
        "print(\"Private Repo:\", PRIVATE_REPO)\n",
        "print(\"Training Container Image:\", TRAIN_IMAGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ApZqSMcbi-2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create request issued for: [test-training]\n",
            "Waiting for operation [projects/ds-dev-jb0001/locations/us-central1/operations/\n",
            "89512de1-7f6d-4e7c-8154-d3e0a2bced37] to complete...done.                      \n",
            "Created repository [test-training].\n"
          ]
        }
      ],
      "source": [
        "!gcloud artifacts repositories create {PRIVATE_REPO} --repository-format=docker --project={PROJECT_ID} --location={REGION} --description=\"Docker repository\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a8DQGNFMjDXf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listing items under project ds-dev-jb0001, across all locations.\n",
            "\n",
            "                                                                     ARTIFACT_REGISTRY\n",
            "REPOSITORY     FORMAT  MODE                 DESCRIPTION        LOCATION     LABELS  ENCRYPTION          CREATE_TIME          UPDATE_TIME          SIZE (MB)\n",
            "test-training  DOCKER  STANDARD_REPOSITORY  Docker repository  us-central1          Google-managed key  2025-11-03T20:57:28  2025-11-03T20:57:28  0\n"
          ]
        }
      ],
      "source": [
        "!gcloud artifacts repositories --project={PROJECT_ID} list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4eC5YUejG4q"
      },
      "source": [
        "## 1-2. Build and push the custom docker container image by using Cloud Build\n",
        "\n",
        "Build and push a Docker image with Cloud Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9u3wTzKjNBC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating temporary archive of 4 file(s) totalling 2.2 KiB before compression.\n",
            "Uploading tarball of [.] to [gs://ds-dev-jb0001_cloudbuild/source/1762204886.607684-62de2d5e3ede428abd2913a816601f62.tgz]\n",
            "Created [https://cloudbuild.googleapis.com/v1/projects/ds-dev-jb0001/locations/us-central1/builds/38e40945-d4f7-4593-80b6-e30aef41e7b3].\n",
            "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/38e40945-d4f7-4593-80b6-e30aef41e7b3?project=277369590897 ].\n",
            "Waiting for build to complete. Polling interval: 1 second(s).\n",
            "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
            "starting build \"38e40945-d4f7-4593-80b6-e30aef41e7b3\"\n",
            "\n",
            "FETCHSOURCE\n",
            "Fetching storage object: gs://ds-dev-jb0001_cloudbuild/source/1762204886.607684-62de2d5e3ede428abd2913a816601f62.tgz#1762204887119271\n",
            "Copying gs://ds-dev-jb0001_cloudbuild/source/1762204886.607684-62de2d5e3ede428abd2913a816601f62.tgz#1762204887119271...\n",
            "/ [1 files][  1.5 KiB/  1.5 KiB]                                                \n",
            "Operation completed over 1 objects/1.5 KiB.\n",
            "BUILD\n",
            "Already have image (with digest): gcr.io/cloud-builders/gcb-internal\n",
            "Sending build context to Docker daemon  6.656kB\n",
            "Step 1/13 : FROM python:3.10.12-slim-bookworm\n",
            "3.10.12-slim-bookworm: Pulling from library/python\n",
            "52d2b7f179e3: Pulling fs layer\n",
            "2b8a9a2240c1: Pulling fs layer\n",
            "618a49bbc6c6: Pulling fs layer\n",
            "708d13076071: Pulling fs layer\n",
            "90b76fc2ebde: Pulling fs layer\n",
            "708d13076071: Waiting\n",
            "90b76fc2ebde: Waiting\n",
            "2b8a9a2240c1: Download complete\n",
            "618a49bbc6c6: Verifying Checksum\n",
            "618a49bbc6c6: Download complete\n",
            "52d2b7f179e3: Verifying Checksum\n",
            "52d2b7f179e3: Download complete\n",
            "708d13076071: Verifying Checksum\n",
            "708d13076071: Download complete\n",
            "90b76fc2ebde: Verifying Checksum\n",
            "90b76fc2ebde: Download complete\n",
            "52d2b7f179e3: Pull complete\n",
            "2b8a9a2240c1: Pull complete\n",
            "618a49bbc6c6: Pull complete\n",
            "708d13076071: Pull complete\n",
            "90b76fc2ebde: Pull complete\n",
            "Digest: sha256:4d440b214e447deddc0a94de23a3d97d28dfafdf125a8b4bb8073381510c9ee2\n",
            "Status: Downloaded newer image for python:3.10.12-slim-bookworm\n",
            " ---> f31204aad672\n",
            "Step 2/13 : RUN apt-get update &&     apt-get install --no-install-suggests --no-install-recommends --yes pipx\n",
            " ---> Running in 4617391fc8af\n",
            "Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]\n",
            "Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]\n",
            "Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]\n",
            "Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8791 kB]\n",
            "Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [6924 B]\n",
            "Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [284 kB]\n",
            "Fetched 9337 kB in 2s (5838 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libpython3-stdlib libpython3.11-minimal libpython3.11-stdlib media-types\n",
            "  python3 python3-argcomplete python3-click python3-colorama python3-distutils\n",
            "  python3-lib2to3 python3-minimal python3-packaging python3-pip-whl\n",
            "  python3-setuptools-whl python3-userpath python3-venv python3.11\n",
            "  python3.11-minimal python3.11-venv\n",
            "Suggested packages:\n",
            "  python3-doc python3-tk python3.11-doc binutils binfmt-support\n",
            "Recommended packages:\n",
            "  fonts-font-awesome libjs-bootstrap4 libjs-highlight.js libjs-jquery\n",
            "  libjs-lunr mkdocs python3-psutil\n",
            "The following NEW packages will be installed:\n",
            "  libpython3-stdlib libpython3.11-minimal libpython3.11-stdlib media-types\n",
            "  pipx python3 python3-argcomplete python3-click python3-colorama\n",
            "  python3-distutils python3-lib2to3 python3-minimal python3-packaging\n",
            "  python3-pip-whl python3-setuptools-whl python3-userpath python3-venv\n",
            "  python3.11 python3.11-minimal python3.11-venv\n",
            "0 upgraded, 20 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 8985 kB of archives.\n",
            "After this operation, 27.8 MB of additional disk space will be used.\n",
            "Get:1 http://deb.debian.org/debian bookworm/main amd64 libpython3.11-minimal amd64 3.11.2-6+deb12u6 [817 kB]\n",
            "Get:2 http://deb.debian.org/debian bookworm/main amd64 python3.11-minimal amd64 3.11.2-6+deb12u6 [2064 kB]\n",
            "Get:3 http://deb.debian.org/debian bookworm/main amd64 python3-minimal amd64 3.11.2-1+b1 [26.3 kB]\n",
            "Get:4 http://deb.debian.org/debian bookworm/main amd64 media-types all 10.0.0 [26.1 kB]\n",
            "Get:5 http://deb.debian.org/debian bookworm/main amd64 libpython3.11-stdlib amd64 3.11.2-6+deb12u6 [1798 kB]\n",
            "Get:6 http://deb.debian.org/debian bookworm/main amd64 python3.11 amd64 3.11.2-6+deb12u6 [573 kB]\n",
            "Get:7 http://deb.debian.org/debian bookworm/main amd64 libpython3-stdlib amd64 3.11.2-1+b1 [9312 B]\n",
            "Get:8 http://deb.debian.org/debian bookworm/main amd64 python3 amd64 3.11.2-1+b1 [26.3 kB]\n",
            "Get:9 http://deb.debian.org/debian bookworm/main amd64 python3-pip-whl all 23.0.1+dfsg-1 [1717 kB]\n",
            "Get:10 http://deb.debian.org/debian bookworm/main amd64 python3-setuptools-whl all 66.1.1-1+deb12u2 [1112 kB]\n",
            "Get:11 http://deb.debian.org/debian bookworm/main amd64 python3-lib2to3 all 3.11.2-3 [76.3 kB]\n",
            "Get:12 http://deb.debian.org/debian bookworm/main amd64 python3-distutils all 3.11.2-3 [131 kB]\n",
            "Get:13 http://deb.debian.org/debian bookworm/main amd64 python3.11-venv amd64 3.11.2-6+deb12u6 [5896 B]\n",
            "Get:14 http://deb.debian.org/debian bookworm/main amd64 python3-venv amd64 3.11.2-1+b1 [1200 B]\n",
            "Get:15 http://deb.debian.org/debian bookworm/main amd64 python3-argcomplete all 2.0.0-1 [34.7 kB]\n",
            "Get:16 http://deb.debian.org/debian bookworm/main amd64 python3-packaging all 23.0-1 [32.5 kB]\n",
            "Get:17 http://deb.debian.org/debian bookworm/main amd64 python3-colorama all 0.4.6-2 [36.8 kB]\n",
            "Get:18 http://deb.debian.org/debian bookworm/main amd64 python3-click all 8.1.3-2 [92.2 kB]\n",
            "Get:19 http://deb.debian.org/debian bookworm/main amd64 python3-userpath all 1.8.0-1 [10.6 kB]\n",
            "Get:20 http://deb.debian.org/debian bookworm/main amd64 pipx all 1.1.0-1 [393 kB]\n",
            "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
            "\u001b[0mFetched 8985 kB in 0s (45.5 MB/s)\n",
            "Selecting previously unselected package libpython3.11-minimal:amd64.\n",
            "(Reading database ... 8386 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.11-minimal_3.11.2-6+deb12u6_amd64.deb ...\n",
            "Unpacking libpython3.11-minimal:amd64 (3.11.2-6+deb12u6) ...\n",
            "Selecting previously unselected package python3.11-minimal.\n",
            "Preparing to unpack .../python3.11-minimal_3.11.2-6+deb12u6_amd64.deb ...\n",
            "Unpacking python3.11-minimal (3.11.2-6+deb12u6) ...\n",
            "Setting up libpython3.11-minimal:amd64 (3.11.2-6+deb12u6) ...\n",
            "Setting up python3.11-minimal (3.11.2-6+deb12u6) ...\n",
            "Selecting previously unselected package python3-minimal.\n",
            "(Reading database ... 8693 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-minimal_3.11.2-1+b1_amd64.deb ...\n",
            "Unpacking python3-minimal (3.11.2-1+b1) ...\n",
            "Selecting previously unselected package media-types.\n",
            "Preparing to unpack .../media-types_10.0.0_all.deb ...\n",
            "Unpacking media-types (10.0.0) ...\n",
            "Selecting previously unselected package libpython3.11-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.11-stdlib_3.11.2-6+deb12u6_amd64.deb ...\n",
            "Unpacking libpython3.11-stdlib:amd64 (3.11.2-6+deb12u6) ...\n",
            "Selecting previously unselected package python3.11.\n",
            "Preparing to unpack .../python3.11_3.11.2-6+deb12u6_amd64.deb ...\n",
            "Unpacking python3.11 (3.11.2-6+deb12u6) ...\n",
            "Selecting previously unselected package libpython3-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3-stdlib_3.11.2-1+b1_amd64.deb ...\n",
            "Unpacking libpython3-stdlib:amd64 (3.11.2-1+b1) ...\n",
            "Setting up python3-minimal (3.11.2-1+b1) ...\n",
            "Selecting previously unselected package python3.\n",
            "(Reading database ... 9103 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python3_3.11.2-1+b1_amd64.deb ...\n",
            "Unpacking python3 (3.11.2-1+b1) ...\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "Preparing to unpack .../01-python3-pip-whl_23.0.1+dfsg-1_all.deb ...\n",
            "Unpacking python3-pip-whl (23.0.1+dfsg-1) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../02-python3-setuptools-whl_66.1.1-1+deb12u2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (66.1.1-1+deb12u2) ...\n",
            "Selecting previously unselected package python3-lib2to3.\n",
            "Preparing to unpack .../03-python3-lib2to3_3.11.2-3_all.deb ...\n",
            "Unpacking python3-lib2to3 (3.11.2-3) ...\n",
            "Selecting previously unselected package python3-distutils.\n",
            "Preparing to unpack .../04-python3-distutils_3.11.2-3_all.deb ...\n",
            "Unpacking python3-distutils (3.11.2-3) ...\n",
            "Selecting previously unselected package python3.11-venv.\n",
            "Preparing to unpack .../05-python3.11-venv_3.11.2-6+deb12u6_amd64.deb ...\n",
            "Unpacking python3.11-venv (3.11.2-6+deb12u6) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../06-python3-venv_3.11.2-1+b1_amd64.deb ...\n",
            "Unpacking python3-venv (3.11.2-1+b1) ...\n",
            "Selecting previously unselected package python3-argcomplete.\n",
            "Preparing to unpack .../07-python3-argcomplete_2.0.0-1_all.deb ...\n",
            "Unpacking python3-argcomplete (2.0.0-1) ...\n",
            "Selecting previously unselected package python3-packaging.\n",
            "Preparing to unpack .../08-python3-packaging_23.0-1_all.deb ...\n",
            "Unpacking python3-packaging (23.0-1) ...\n",
            "Selecting previously unselected package python3-colorama.\n",
            "Preparing to unpack .../09-python3-colorama_0.4.6-2_all.deb ...\n",
            "Unpacking python3-colorama (0.4.6-2) ...\n",
            "Selecting previously unselected package python3-click.\n",
            "Preparing to unpack .../10-python3-click_8.1.3-2_all.deb ...\n",
            "Unpacking python3-click (8.1.3-2) ...\n",
            "Selecting previously unselected package python3-userpath.\n",
            "Preparing to unpack .../11-python3-userpath_1.8.0-1_all.deb ...\n",
            "Unpacking python3-userpath (1.8.0-1) ...\n",
            "Selecting previously unselected package pipx.\n",
            "Preparing to unpack .../12-pipx_1.1.0-1_all.deb ...\n",
            "Unpacking pipx (1.1.0-1) ...\n",
            "Setting up media-types (10.0.0) ...\n",
            "Setting up python3-setuptools-whl (66.1.1-1+deb12u2) ...\n",
            "Setting up python3-pip-whl (23.0.1+dfsg-1) ...\n",
            "Setting up libpython3.11-stdlib:amd64 (3.11.2-6+deb12u6) ...\n",
            "Setting up libpython3-stdlib:amd64 (3.11.2-1+b1) ...\n",
            "Setting up python3.11 (3.11.2-6+deb12u6) ...\n",
            "Setting up python3 (3.11.2-1+b1) ...\n",
            "running python rtupdate hooks for python3.11...\n",
            "running python post-rtupdate hooks for python3.11...\n",
            "Setting up python3-packaging (23.0-1) ...\n",
            "Setting up python3-argcomplete (2.0.0-1) ...\n",
            "Setting up python3-lib2to3 (3.11.2-3) ...\n",
            "Setting up python3-distutils (3.11.2-3) ...\n",
            "Setting up python3-colorama (0.4.6-2) ...\n",
            "Setting up python3-click (8.1.3-2) ...\n",
            "Setting up python3.11-venv (3.11.2-6+deb12u6) ...\n",
            "Setting up python3-userpath (1.8.0-1) ...\n",
            "Setting up python3-venv (3.11.2-1+b1) ...\n",
            "Setting up pipx (1.1.0-1) ...\n",
            "Removing intermediate container 4617391fc8af\n",
            " ---> 56880760ccab\n",
            "Step 3/13 : RUN apt-get update &&     apt-get install -y net-tools iputils-ping tcpdump dnsutils\n",
            " ---> Running in b3460f9c0958\n",
            "Hit:1 http://deb.debian.org/debian bookworm InRelease\n",
            "Hit:2 http://deb.debian.org/debian bookworm-updates InRelease\n",
            "Hit:3 http://deb.debian.org/debian-security bookworm-security InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  bind9-dnsutils bind9-host bind9-libs dbus dbus-bin dbus-daemon\n",
            "  dbus-session-bus-common dbus-system-bus-common libapparmor1 libbsd0 libcap2\n",
            "  libcap2-bin libdbus-1-3 libedit2 libfstrm0 libicu72 libjemalloc2 libjson-c5\n",
            "  liblmdb0 libmaxminddb0 libnghttp2-14 libpam-cap libpcap0.8 libprotobuf-c1\n",
            "  libuv1 libxml2\n",
            "Suggested packages:\n",
            "  default-dbus-session-bus | dbus-session-bus mmdb-bin apparmor\n",
            "The following NEW packages will be installed:\n",
            "  bind9-dnsutils bind9-host bind9-libs dbus dbus-bin dbus-daemon\n",
            "  dbus-session-bus-common dbus-system-bus-common dnsutils iputils-ping\n",
            "  libapparmor1 libbsd0 libcap2-bin libdbus-1-3 libedit2 libfstrm0 libicu72\n",
            "  libjemalloc2 libjson-c5 liblmdb0 libmaxminddb0 libnghttp2-14 libpam-cap\n",
            "  libpcap0.8 libprotobuf-c1 libuv1 libxml2 net-tools tcpdump\n",
            "The following packages will be upgraded:\n",
            "  libcap2\n",
            "1 upgraded, 29 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 14.1 MB of archives.\n",
            "After this operation, 50.2 MB of additional disk space will be used.\n",
            "Get:1 http://deb.debian.org/debian bookworm/main amd64 libdbus-1-3 amd64 1.14.10-1~deb12u1 [201 kB]\n",
            "Get:2 http://deb.debian.org/debian bookworm/main amd64 dbus-bin amd64 1.14.10-1~deb12u1 [105 kB]\n",
            "Get:3 http://deb.debian.org/debian bookworm/main amd64 dbus-session-bus-common all 1.14.10-1~deb12u1 [78.2 kB]\n",
            "Get:4 http://deb.debian.org/debian bookworm/main amd64 libapparmor1 amd64 3.0.8-3 [41.2 kB]\n",
            "Get:5 http://deb.debian.org/debian bookworm/main amd64 dbus-daemon amd64 1.14.10-1~deb12u1 [184 kB]\n",
            "Get:6 http://deb.debian.org/debian bookworm/main amd64 dbus-system-bus-common all 1.14.10-1~deb12u1 [79.3 kB]\n",
            "Get:7 http://deb.debian.org/debian bookworm/main amd64 dbus amd64 1.14.10-1~deb12u1 [97.4 kB]\n",
            "Get:8 http://deb.debian.org/debian bookworm/main amd64 libcap2 amd64 1:2.66-4+deb12u2 [27.2 kB]\n",
            "Get:9 http://deb.debian.org/debian bookworm/main amd64 libcap2-bin amd64 1:2.66-4+deb12u2 [34.9 kB]\n",
            "Get:10 http://deb.debian.org/debian bookworm/main amd64 iputils-ping amd64 3:20221126-1+deb12u1 [47.2 kB]\n",
            "Get:11 http://deb.debian.org/debian bookworm/main amd64 libuv1 amd64 1.44.2-1+deb12u1 [136 kB]\n",
            "Get:12 http://deb.debian.org/debian bookworm/main amd64 libfstrm0 amd64 0.6.1-1 [21.6 kB]\n",
            "Get:13 http://deb.debian.org/debian bookworm/main amd64 libjemalloc2 amd64 5.3.0-1 [275 kB]\n",
            "Get:14 http://deb.debian.org/debian bookworm/main amd64 libjson-c5 amd64 0.16-2 [44.1 kB]\n",
            "Get:15 http://deb.debian.org/debian bookworm/main amd64 liblmdb0 amd64 0.9.24-1 [45.0 kB]\n",
            "Get:16 http://deb.debian.org/debian bookworm/main amd64 libmaxminddb0 amd64 1.7.1-1 [29.8 kB]\n",
            "Get:17 http://deb.debian.org/debian bookworm/main amd64 libnghttp2-14 amd64 1.52.0-1+deb12u2 [73.0 kB]\n",
            "Get:18 http://deb.debian.org/debian bookworm/main amd64 libprotobuf-c1 amd64 1.4.1-1+b1 [27.5 kB]\n",
            "Get:19 http://deb.debian.org/debian bookworm/main amd64 libicu72 amd64 72.1-3+deb12u1 [9376 kB]\n",
            "Get:20 http://deb.debian.org/debian bookworm/main amd64 libxml2 amd64 2.9.14+dfsg-1.3~deb12u4 [687 kB]\n",
            "Get:21 http://deb.debian.org/debian-security bookworm-security/main amd64 bind9-libs amd64 1:9.18.41-1~deb12u1 [1181 kB]\n",
            "Get:22 http://deb.debian.org/debian-security bookworm-security/main amd64 bind9-host amd64 1:9.18.41-1~deb12u1 [54.7 kB]\n",
            "Get:23 http://deb.debian.org/debian bookworm/main amd64 libbsd0 amd64 0.11.7-2 [117 kB]\n",
            "Get:24 http://deb.debian.org/debian bookworm/main amd64 libedit2 amd64 3.1-20221030-2 [93.0 kB]\n",
            "Get:25 http://deb.debian.org/debian-security bookworm-security/main amd64 bind9-dnsutils amd64 1:9.18.41-1~deb12u1 [155 kB]\n",
            "Get:26 http://deb.debian.org/debian-security bookworm-security/main amd64 dnsutils all 1:9.18.41-1~deb12u1 [11.2 kB]\n",
            "Get:27 http://deb.debian.org/debian bookworm/main amd64 libpam-cap amd64 1:2.66-4+deb12u2 [14.7 kB]\n",
            "Get:28 http://deb.debian.org/debian bookworm/main amd64 libpcap0.8 amd64 1.10.3-1 [157 kB]\n",
            "Get:29 http://deb.debian.org/debian bookworm/main amd64 net-tools amd64 2.10-0.1+deb12u2 [243 kB]\n",
            "Get:30 http://deb.debian.org/debian bookworm/main amd64 tcpdump amd64 4.99.3-1 [467 kB]\n",
            "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
            "\u001b[0mFetched 14.1 MB in 0s (61.6 MB/s)\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "(Reading database ... 9510 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libdbus-1-3_1.14.10-1~deb12u1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.14.10-1~deb12u1) ...\n",
            "Selecting previously unselected package dbus-bin.\n",
            "Preparing to unpack .../1-dbus-bin_1.14.10-1~deb12u1_amd64.deb ...\n",
            "Unpacking dbus-bin (1.14.10-1~deb12u1) ...\n",
            "Selecting previously unselected package dbus-session-bus-common.\n",
            "Preparing to unpack .../2-dbus-session-bus-common_1.14.10-1~deb12u1_all.deb ...\n",
            "Unpacking dbus-session-bus-common (1.14.10-1~deb12u1) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../3-libapparmor1_3.0.8-3_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (3.0.8-3) ...\n",
            "Selecting previously unselected package dbus-daemon.\n",
            "Preparing to unpack .../4-dbus-daemon_1.14.10-1~deb12u1_amd64.deb ...\n",
            "Unpacking dbus-daemon (1.14.10-1~deb12u1) ...\n",
            "Selecting previously unselected package dbus-system-bus-common.\n",
            "Preparing to unpack .../5-dbus-system-bus-common_1.14.10-1~deb12u1_all.deb ...\n",
            "Unpacking dbus-system-bus-common (1.14.10-1~deb12u1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../6-dbus_1.14.10-1~deb12u1_amd64.deb ...\n",
            "Unpacking dbus (1.14.10-1~deb12u1) ...\n",
            "Preparing to unpack .../7-libcap2_1%3a2.66-4+deb12u2_amd64.deb ...\n",
            "Unpacking libcap2:amd64 (1:2.66-4+deb12u2) over (1:2.66-4) ...\n",
            "Setting up libcap2:amd64 (1:2.66-4+deb12u2) ...\n",
            "Selecting previously unselected package libcap2-bin.\n",
            "(Reading database ... 9596 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libcap2-bin_1%3a2.66-4+deb12u2_amd64.deb ...\n",
            "Unpacking libcap2-bin (1:2.66-4+deb12u2) ...\n",
            "Selecting previously unselected package iputils-ping.\n",
            "Preparing to unpack .../01-iputils-ping_3%3a20221126-1+deb12u1_amd64.deb ...\n",
            "Unpacking iputils-ping (3:20221126-1+deb12u1) ...\n",
            "Selecting previously unselected package libuv1:amd64.\n",
            "Preparing to unpack .../02-libuv1_1.44.2-1+deb12u1_amd64.deb ...\n",
            "Unpacking libuv1:amd64 (1.44.2-1+deb12u1) ...\n",
            "Selecting previously unselected package libfstrm0:amd64.\n",
            "Preparing to unpack .../03-libfstrm0_0.6.1-1_amd64.deb ...\n",
            "Unpacking libfstrm0:amd64 (0.6.1-1) ...\n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "Preparing to unpack .../04-libjemalloc2_5.3.0-1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.3.0-1) ...\n",
            "Selecting previously unselected package libjson-c5:amd64.\n",
            "Preparing to unpack .../05-libjson-c5_0.16-2_amd64.deb ...\n",
            "Unpacking libjson-c5:amd64 (0.16-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../06-liblmdb0_0.9.24-1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.24-1) ...\n",
            "Selecting previously unselected package libmaxminddb0:amd64.\n",
            "Preparing to unpack .../07-libmaxminddb0_1.7.1-1_amd64.deb ...\n",
            "Unpacking libmaxminddb0:amd64 (1.7.1-1) ...\n",
            "Selecting previously unselected package libnghttp2-14:amd64.\n",
            "Preparing to unpack .../08-libnghttp2-14_1.52.0-1+deb12u2_amd64.deb ...\n",
            "Unpacking libnghttp2-14:amd64 (1.52.0-1+deb12u2) ...\n",
            "Selecting previously unselected package libprotobuf-c1:amd64.\n",
            "Preparing to unpack .../09-libprotobuf-c1_1.4.1-1+b1_amd64.deb ...\n",
            "Unpacking libprotobuf-c1:amd64 (1.4.1-1+b1) ...\n",
            "Selecting previously unselected package libicu72:amd64.\n",
            "Preparing to unpack .../10-libicu72_72.1-3+deb12u1_amd64.deb ...\n",
            "Unpacking libicu72:amd64 (72.1-3+deb12u1) ...\n",
            "Selecting previously unselected package libxml2:amd64.\n",
            "Preparing to unpack .../11-libxml2_2.9.14+dfsg-1.3~deb12u4_amd64.deb ...\n",
            "Unpacking libxml2:amd64 (2.9.14+dfsg-1.3~deb12u4) ...\n",
            "Selecting previously unselected package bind9-libs:amd64.\n",
            "Preparing to unpack .../12-bind9-libs_1%3a9.18.41-1~deb12u1_amd64.deb ...\n",
            "Unpacking bind9-libs:amd64 (1:9.18.41-1~deb12u1) ...\n",
            "Selecting previously unselected package bind9-host.\n",
            "Preparing to unpack .../13-bind9-host_1%3a9.18.41-1~deb12u1_amd64.deb ...\n",
            "Unpacking bind9-host (1:9.18.41-1~deb12u1) ...\n",
            "Selecting previously unselected package libbsd0:amd64.\n",
            "Preparing to unpack .../14-libbsd0_0.11.7-2_amd64.deb ...\n",
            "Unpacking libbsd0:amd64 (0.11.7-2) ...\n",
            "Selecting previously unselected package libedit2:amd64.\n",
            "Preparing to unpack .../15-libedit2_3.1-20221030-2_amd64.deb ...\n",
            "Unpacking libedit2:amd64 (3.1-20221030-2) ...\n",
            "Selecting previously unselected package bind9-dnsutils.\n",
            "Preparing to unpack .../16-bind9-dnsutils_1%3a9.18.41-1~deb12u1_amd64.deb ...\n",
            "Unpacking bind9-dnsutils (1:9.18.41-1~deb12u1) ...\n",
            "Selecting previously unselected package dnsutils.\n",
            "Preparing to unpack .../17-dnsutils_1%3a9.18.41-1~deb12u1_all.deb ...\n",
            "Unpacking dnsutils (1:9.18.41-1~deb12u1) ...\n",
            "Selecting previously unselected package libpam-cap:amd64.\n",
            "Preparing to unpack .../18-libpam-cap_1%3a2.66-4+deb12u2_amd64.deb ...\n",
            "Unpacking libpam-cap:amd64 (1:2.66-4+deb12u2) ...\n",
            "Selecting previously unselected package libpcap0.8:amd64.\n",
            "Preparing to unpack .../19-libpcap0.8_1.10.3-1_amd64.deb ...\n",
            "Unpacking libpcap0.8:amd64 (1.10.3-1) ...\n",
            "Selecting previously unselected package net-tools.\n",
            "Preparing to unpack .../20-net-tools_2.10-0.1+deb12u2_amd64.deb ...\n",
            "Unpacking net-tools (2.10-0.1+deb12u2) ...\n",
            "Selecting previously unselected package tcpdump.\n",
            "Preparing to unpack .../21-tcpdump_4.99.3-1_amd64.deb ...\n",
            "Unpacking tcpdump (4.99.3-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.24-1) ...\n",
            "Setting up net-tools (2.10-0.1+deb12u2) ...\n",
            "Setting up libapparmor1:amd64 (3.0.8-3) ...\n",
            "Setting up libicu72:amd64 (72.1-3+deb12u1) ...\n",
            "Setting up libmaxminddb0:amd64 (1.7.1-1) ...\n",
            "Setting up libfstrm0:amd64 (0.6.1-1) ...\n",
            "Setting up libnghttp2-14:amd64 (1.52.0-1+deb12u2) ...\n",
            "Setting up libjemalloc2:amd64 (5.3.0-1) ...\n",
            "Setting up libprotobuf-c1:amd64 (1.4.1-1+b1) ...\n",
            "Setting up libcap2-bin (1:2.66-4+deb12u2) ...\n",
            "Setting up libuv1:amd64 (1.44.2-1+deb12u1) ...\n",
            "Setting up libdbus-1-3:amd64 (1.14.10-1~deb12u1) ...\n",
            "Setting up dbus-session-bus-common (1.14.10-1~deb12u1) ...\n",
            "Setting up dbus-system-bus-common (1.14.10-1~deb12u1) ...\n",
            "Setting up libbsd0:amd64 (0.11.7-2) ...\n",
            "Setting up libpam-cap:amd64 (1:2.66-4+deb12u2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.36.0 /usr/local/share/perl/5.36.0 /usr/lib/x86_64-linux-gnu/perl5/5.36 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.36 /usr/share/perl/5.36 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "Setting up iputils-ping (3:20221126-1+deb12u1) ...\n",
            "Setting up libjson-c5:amd64 (0.16-2) ...\n",
            "Setting up libxml2:amd64 (2.9.14+dfsg-1.3~deb12u4) ...\n",
            "Setting up dbus-bin (1.14.10-1~deb12u1) ...\n",
            "Setting up bind9-libs:amd64 (1:9.18.41-1~deb12u1) ...\n",
            "Setting up libedit2:amd64 (3.1-20221030-2) ...\n",
            "Setting up dbus-daemon (1.14.10-1~deb12u1) ...\n",
            "Setting up libpcap0.8:amd64 (1.10.3-1) ...\n",
            "Setting up dbus (1.14.10-1~deb12u1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up bind9-host (1:9.18.41-1~deb12u1) ...\n",
            "Setting up tcpdump (4.99.3-1) ...\n",
            "Setting up bind9-dnsutils (1:9.18.41-1~deb12u1) ...\n",
            "Setting up dnsutils (1:9.18.41-1~deb12u1) ...\n",
            "Processing triggers for libc-bin (2.36-9+deb12u1) ...\n",
            "Removing intermediate container b3460f9c0958\n",
            " ---> 1d9acaf222de\n",
            "Step 4/13 : ENV PATH=\"/root/.local/bin:${PATH}\"\n",
            " ---> Running in 402f719bf21f\n",
            "Removing intermediate container 402f719bf21f\n",
            " ---> 75f7b80246cb\n",
            "Step 5/13 : RUN pipx install poetry\n",
            " ---> Running in a0ed6f401c57\n",
            "\u001b[91mcreating virtual environment...\n",
            "\u001b[0m\u001b[91mcreating shared libraries...\n",
            "\u001b[0m\u001b[91mupgrading shared libraries...\n",
            "\u001b[0m\u001b[91minstalling poetry...\n",
            "\u001b[0m\u001b[91mdone! ✨ 🌟 ✨\n",
            "\u001b[0m  installed package poetry 2.2.1, installed using Python 3.11.2\n",
            "  These apps are now globally available\n",
            "    - poetry\n",
            "Removing intermediate container a0ed6f401c57\n",
            " ---> 032a37e51c4e\n",
            "Step 6/13 : RUN pipx inject poetry poetry-plugin-bundle\n",
            " ---> Running in 46bd1cac8198\n",
            "\u001b[91minstalling poetry-plugin-bundle...\n",
            "\u001b[0m\u001b[91mdone! ✨ 🌟 ✨\n",
            "\u001b[0m  injected package poetry-plugin-bundle into venv poetry\n",
            "Removing intermediate container 46bd1cac8198\n",
            " ---> 993bc1459399\n",
            "Step 7/13 : ENV POETRY_NO_INTERACTION=1     POETRY_VIRTUALENVS_IN_PROJECT=1     POETRY_VIRTUALENVS_CREATE=1     POETRY_CACHE_DIR=/tmp/poetry_cache\n",
            " ---> Running in 2c81ca76164d\n",
            "Removing intermediate container 2c81ca76164d\n",
            " ---> 748537dd7dc2\n",
            "Step 8/13 : WORKDIR /\n",
            " ---> Running in 33a2a6f37bbb\n",
            "Removing intermediate container 33a2a6f37bbb\n",
            " ---> 72ac645e0990\n",
            "Step 9/13 : COPY pyproject.toml .\n",
            " ---> 768b0a2d805d\n",
            "Step 10/13 : RUN poetry install --no-root && rm -rf $POETRY_CACHE_DIR\n",
            " ---> Running in fb7a9f8c6700\n",
            "\u001b[91mCreating virtualenv non-package-mode in /.venv\n",
            "\u001b[0mUpdating dependencies\n",
            "Resolving dependencies...\n",
            "\n",
            "Writing lock file\n",
            "Removing intermediate container fb7a9f8c6700\n",
            " ---> ac95d04fd298\n",
            "Step 11/13 : ENV VIRTUAL_ENV=/.venv     PATH=\"/.venv/bin:$PATH\"\n",
            " ---> Running in 582ff16ce2fb\n",
            "Removing intermediate container 582ff16ce2fb\n",
            " ---> 54e1f21a6963\n",
            "Step 12/13 : COPY trainer /trainer\n",
            " ---> 33a163230241\n",
            "Step 13/13 : ENTRYPOINT [ \"poetry\", \"run\", \"python\", \"-m\", \"trainer.train\" ]\n",
            " ---> Running in e11474171779\n",
            "Removing intermediate container e11474171779\n",
            " ---> d36cc9f6e7e2\n",
            "Successfully built d36cc9f6e7e2\n",
            "Successfully tagged us-central1-docker.pkg.dev/ds-dev-jb0001/test-training/test:latest\n",
            "PUSH\n",
            "Pushing us-central1-docker.pkg.dev/ds-dev-jb0001/test-training/test:latest\n",
            "The push refers to repository [us-central1-docker.pkg.dev/ds-dev-jb0001/test-training/test]\n",
            "6fca8dd0f410: Preparing\n",
            "b38e111cbd3e: Preparing\n",
            "fef145e70c16: Preparing\n",
            "67353985b23a: Preparing\n",
            "963d76fe7f1e: Preparing\n",
            "759f4b18e84c: Preparing\n",
            "b77366364de4: Preparing\n",
            "54512d0df01f: Preparing\n",
            "43574d3b4af9: Preparing\n",
            "1b9e3cebd93c: Preparing\n",
            "5b60283f3630: Preparing\n",
            "511780f88f80: Preparing\n",
            "54512d0df01f: Waiting\n",
            "43574d3b4af9: Waiting\n",
            "1b9e3cebd93c: Waiting\n",
            "759f4b18e84c: Waiting\n",
            "b77366364de4: Waiting\n",
            "5b60283f3630: Waiting\n",
            "511780f88f80: Waiting\n",
            "67353985b23a: Pushed\n",
            "fef145e70c16: Pushed\n",
            "6fca8dd0f410: Pushed\n",
            "b38e111cbd3e: Pushed\n",
            "43574d3b4af9: Pushed\n",
            "54512d0df01f: Pushed\n",
            "759f4b18e84c: Pushed\n",
            "5b60283f3630: Pushed\n",
            "b77366364de4: Pushed\n",
            "1b9e3cebd93c: Pushed\n",
            "511780f88f80: Pushed\n",
            "963d76fe7f1e: Pushed\n",
            "latest: digest: sha256:4d44ba81369d82f4def6c97aa570ba09588eae401d4e5ab456f7f8f68b6e47b5 size: 2841\n",
            "DONE\n",
            "--------------------------------------------------------------------------------\n",
            "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                                 STATUS\n",
            "38e40945-d4f7-4593-80b6-e30aef41e7b3  2025-11-03T21:21:27+00:00  1M20S     gs://ds-dev-jb0001_cloudbuild/source/1762204886.607684-62de2d5e3ede428abd2913a816601f62.tgz  us-central1-docker.pkg.dev/ds-dev-jb0001/test-training/test (+1 more)  SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!cd $CONTAINER_DIR && gcloud builds submit --timeout=1800s --project={PROJECT_ID} --region={IMAGE_REGION} --tag {TRAIN_IMAGE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpT8ae9a-mMe"
      },
      "source": [
        "# 2-0. Set up private services access for your VPC\n",
        "\n",
        "Following this guide for [setting up a Private Service Connect interface for Vertex AI resources](https://cloud.google.com/vertex-ai/docs/general/vpc-psc-i-setup)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nYUVceYtTVBm"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER_VPC_HOST = !(gcloud projects describe $PROJECT_ID_VPC_HOST --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER_VPC_HOST = PROJECT_NUMBER_VPC_HOST[0]\n",
        "\n",
        "PROJECT_NUMBER = !(gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "21ivCT6dMOX5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ID: ds-dev-jb0001\n",
            "PROJECT_NUMBER: 277369590897\n",
            "----------\n",
            "PROJECT_ID_VPC_HOST: jb01-shared-vpc-dev\n",
            "PROJECT_NUMBER_VPC_HOST: 546029343527\n"
          ]
        }
      ],
      "source": [
        "print(\"PROJECT_ID:\", PROJECT_ID)\n",
        "print(\"PROJECT_NUMBER:\", PROJECT_NUMBER)\n",
        "print(\"----------\")\n",
        "print(\"PROJECT_ID_VPC_HOST:\", PROJECT_ID_VPC_HOST)\n",
        "print(\"PROJECT_NUMBER_VPC_HOST:\", PROJECT_NUMBER_VPC_HOST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HjEoATQUEeEj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "projects/546029343527/regions/us-central1/networkAttachments/us-central1-vertex-psci\n",
            "projects/546029343527/regions/us-west1/networkAttachments/us-west1-vertex-psci\n"
          ]
        }
      ],
      "source": [
        "FULL_NETWORK_ATTACHMENT_NAME_CENTRAL = f\"projects/{PROJECT_NUMBER_VPC_HOST}/regions/{REGION_CENTRAL}/networkAttachments/{NETWORK_ATTACHMENT_NAME_CENTRAL}\"\n",
        "FULL_NETWORK_ATTACHMENT_NAME_WEST = f\"projects/{PROJECT_NUMBER_VPC_HOST}/regions/{REGION_WEST}/networkAttachments/{NETWORK_ATTACHMENT_NAME_WEST}\"\n",
        "\n",
        "print(FULL_NETWORK_ATTACHMENT_NAME_CENTRAL)\n",
        "print(FULL_NETWORK_ATTACHMENT_NAME_WEST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e30V9DP2fCSk"
      },
      "source": [
        "## 2-3. List Subnets\n",
        "These should have been created with terraform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LSRzCEZF-rsy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                     REGION       NETWORK         RANGE        STACK_TYPE  IPV6_ACCESS_TYPE  INTERNAL_IPV6_PREFIX  EXTERNAL_IPV6_PREFIX  UTILIZATION_DETAILS\n",
            "us-central1-vertex-psci  us-central1  vertex-vpc-dev  10.0.0.0/24  IPV4_ONLY\n"
          ]
        }
      ],
      "source": [
        "!gcloud compute networks subnets list --project={PROJECT_ID_VPC_HOST}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S7z_USIkgbe"
      },
      "source": [
        "## 2-4. List Network Attachments\n",
        "\n",
        "These should have been created with terraform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "whEGZOjAza8V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                     REGION       CONNECTION_PREFERENCE\n",
            "us-central1-vertex-psci  us-central1  ACCEPT_AUTOMATIC\n"
          ]
        }
      ],
      "source": [
        "!gcloud compute network-attachments list --project={PROJECT_ID_VPC_HOST}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkAML_EJip5w"
      },
      "outputs": [],
      "source": [
        "# @title [Optional]: Setup your NFS instance\n",
        "# !gcloud config set filestore/zone {ZONE}\n",
        "\n",
        "# !gcloud filestore instances create {INSTANCE_NAME} \\\n",
        "#     --tier=TIER \\\n",
        "#     --file-share=name=\"file_share_name\",capacity={SIZE} \\\n",
        "#     --network=name={NETWORK}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlNDREt4hx3W"
      },
      "source": [
        "# 3-0. Run custom training jobs with PSC-I\n",
        "\n",
        "This section creates a custom training job with a Private Service Connect interface. View the [documentation page](https://cloud.google.com/vertex-ai/docs/training/psc-i-egress) for the most up to date information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw4edKzOjWx8"
      },
      "source": [
        "## 3-1. Prepare training jobs\n",
        "\n",
        "Vertex AI Training supports submiting custom training jobs with a prebuilt container, custom container and python application via **HTTP request, Vertex AI SDK or gcloud CLI**. Learn more [here](https://cloud.google.com/vertex-ai/docs/training/code-requirements).\n",
        "\n",
        "In this example, we will demonstrate how to run a custom job with with custom containers. Please specify the images below to your custom images.\n",
        "Note, if it's not a public image, please ensure it's already pushed to your project.\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/training/containers-overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RMxA4ortWUhR"
      },
      "outputs": [],
      "source": [
        "# @title Function Defs\n",
        "### Create CPU Test Training Job\n",
        "def create_single_replica_cpu_job(project_id: str, region: str, network_peering: str = None, network_attachment: str = None, enable_web_access: bool = False):\n",
        "  ############ Set Job Service Endpoint ################\n",
        "  endpoint= f\"{region}-aiplatform.googleapis.com\"\n",
        "  job_request_uri = f\"https://{endpoint}/v1beta1/projects/{project_id}/locations/{region}/customJobs\"\n",
        "\n",
        "  bearer_token = !gcloud auth application-default print-access-token\n",
        "  headers = {\n",
        "      'Content-Type': 'application/json',\n",
        "      'Authorization': 'Bearer {}'.format(bearer_token[0]),\n",
        "  }\n",
        "\n",
        "  print(\"Calling endpoint: {} to create custom training job\".format(job_request_uri))\n",
        "  cpu_single_job = {\n",
        "    \"display_name\": \"CPU Test Job\",\n",
        "    \"job_spec\": {\n",
        "        \"worker_pool_specs\": [\n",
        "          CPU_WORKER_SPEC,\n",
        "        ],\n",
        "        \"service_account\": TRAINING_SA,\n",
        "    },\n",
        "    \"labels\": {\n",
        "        \"network_type\": \"none\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if network_attachment and (network_peering == None):\n",
        "    psc_interface_config = {\n",
        "        \"network_attachment\": network_attachment\n",
        "    }\n",
        "    labels = {\n",
        "        \"network_type\": \"psc-i\"\n",
        "    }\n",
        "    cpu_single_job[\"display_name\"] = \"CPU Test Job PSC-I\"\n",
        "    cpu_single_job[\"job_spec\"][\"psc_interface_config\"] = psc_interface_config\n",
        "    cpu_single_job[\"labels\"] = labels\n",
        "\n",
        "  if (network_attachment == None) and network_peering:\n",
        "    labels = {\n",
        "        \"network_type\": \"peering\"\n",
        "    }\n",
        "    cpu_single_job[\"display_name\"] = \"CPU Test Job Peering\"\n",
        "    cpu_single_job[\"job_spec\"][\"network\"] = network_peering\n",
        "    cpu_single_job[\"labels\"] = labels\n",
        "\n",
        "  if enable_web_access:\n",
        "    cpu_single_job[\"job_spec\"][\"enable_web_access\"] = enable_web_access\n",
        "\n",
        "  print(json.dumps(cpu_single_job, indent=2))\n",
        "\n",
        "  response = requests.post(job_request_uri, json=cpu_single_job, headers=headers)\n",
        "\n",
        "  print(\"response:\", response)\n",
        "  job_name = None\n",
        "  job_id = None\n",
        "  if response.reason == 'OK':\n",
        "    job_name = response.json()['name']\n",
        "    job_id = job_name.split('/')[-1]\n",
        "    url = f\"console.cloud.google.com/vertex-ai/locations/{region}/training/{job_id}/cpu?&project={project_id}\"\n",
        "    print(\"Created Job: \", response.json()['name'])\n",
        "    print(\"Link:\", \"https://\"+url)\n",
        "  else:\n",
        "    print(response.text)\n",
        "  return job_name, job_id, response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mGPDSgvyl7d-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Private Repo: vertex-training-test\n",
            "Training Container Image: us-docker.pkg.dev/ds-dev-jb0001/vertex-training-test/test:latest\n"
          ]
        }
      ],
      "source": [
        "# Repo to create / use for running training job\n",
        "PRIVATE_REPO = \"vertex-training-test\"\n",
        "TRAIN_IMAGE = (\n",
        "    f\"{IMAGE_REGION}-docker.pkg.dev/{PROJECT_ID}/{PRIVATE_REPO}/test:latest\"\n",
        ")\n",
        "print(\"Private Repo:\", PRIVATE_REPO)\n",
        "print(\"Training Container Image:\", TRAIN_IMAGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "q0Hc9yY8no9p"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER_VPC_HOST = !(gcloud projects describe $PROJECT_ID_VPC_HOST --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER_VPC_HOST = PROJECT_NUMBER_VPC_HOST[0]\n",
        "\n",
        "PROJECT_NUMBER = !(gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yCmWBM7Qno9q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ID: ds-dev-jb0001\n",
            "PROJECT_NUMBER: 277369590897\n",
            "----------\n",
            "PROJECT_ID_VPC_HOST: jb01-shared-vpc-dev\n",
            "PROJECT_NUMBER_VPC_HOST: 546029343527\n"
          ]
        }
      ],
      "source": [
        "print(\"PROJECT_ID:\", PROJECT_ID)\n",
        "print(\"PROJECT_NUMBER:\", PROJECT_NUMBER)\n",
        "print(\"----------\")\n",
        "print(\"PROJECT_ID_VPC_HOST:\", PROJECT_ID_VPC_HOST)\n",
        "print(\"PROJECT_NUMBER_VPC_HOST:\", PROJECT_NUMBER_VPC_HOST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3XLvaWRMno9r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "projects/546029343527/regions/us-central1/networkAttachments/us-central1-vertex-psci\n",
            "projects/546029343527/regions/us-west1/networkAttachments/us-west1-vertex-psci\n"
          ]
        }
      ],
      "source": [
        "FULL_NETWORK_ATTACHMENT_NAME_CENTRAL = f\"projects/{PROJECT_NUMBER_VPC_HOST}/regions/{REGION_CENTRAL}/networkAttachments/{NETWORK_ATTACHMENT_NAME_CENTRAL}\"\n",
        "FULL_NETWORK_ATTACHMENT_NAME_WEST = f\"projects/{PROJECT_NUMBER_VPC_HOST}/regions/{REGION_WEST}/networkAttachments/{NETWORK_ATTACHMENT_NAME_WEST}\"\n",
        "\n",
        "print(FULL_NETWORK_ATTACHMENT_NAME_CENTRAL)\n",
        "print(FULL_NETWORK_ATTACHMENT_NAME_WEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5SfzF67Fjm8Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using image:  us-docker.pkg.dev/ds-dev-jb0001/vertex-training-test/test:latest\n",
            "Network Attachment in us-central1: projects/546029343527/regions/us-central1/networkAttachments/us-central1-vertex-psci\n",
            "Network Attachment in us-west1: projects/546029343527/regions/us-west1/networkAttachments/us-west1-vertex-psci\n"
          ]
        }
      ],
      "source": [
        "# Prepare training images\n",
        "CPU_IMAGE = TRAIN_IMAGE\n",
        "print(\"Using image: \", CPU_IMAGE)\n",
        "print(f\"Network Attachment in {REGION_CENTRAL}: {FULL_NETWORK_ATTACHMENT_NAME_CENTRAL}\")\n",
        "print(f\"Network Attachment in {REGION_WEST}: {FULL_NETWORK_ATTACHMENT_NAME_WEST}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZZO_lSSmMdn"
      },
      "source": [
        "## 3-2. Training Job Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OMG8KbGnmm4C"
      },
      "outputs": [],
      "source": [
        "CPU_MACHINE_TYPE = \"n2-standard-4\"  # @param {type:\"string\"}\n",
        "TRAINING_SA = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQnfz8q4WvL_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU worker spec:\n",
            " {\n",
            "  \"machine_spec\": {\n",
            "    \"machine_type\": \"n2-standard-4\"\n",
            "  },\n",
            "  \"replica_count\": 1,\n",
            "  \"container_spec\": {\n",
            "    \"image_uri\": \"us-docker.pkg.dev/ds-dev-jb0001/vertex-training-test/test:latest\",\n",
            "    \"command\": [],\n",
            "    \"args\": [\n",
            "      \"--sleep=1200s\"\n",
            "    ]\n",
            "  },\n",
            "  \"disk_spec\": {\n",
            "    \"boot_disk_type\": \"pd-ssd\",\n",
            "    \"boot_disk_size_gb\": 100\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# This is consistent with the default disk spec of jobs.\n",
        "DISK_SPEC = {\n",
        "  \"boot_disk_type\": \"pd-ssd\",\n",
        "  \"boot_disk_size_gb\": 100\n",
        "}\n",
        "\n",
        "############ Set WorkerPool Spec #####################\n",
        "# https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec\n",
        "CPU_WORKER_SPEC = {\n",
        "  \"machine_spec\": {\n",
        "    \"machine_type\": CPU_MACHINE_TYPE,\n",
        "  },\n",
        "  \"replica_count\": 1,\n",
        "  \"container_spec\": {\n",
        "    \"image_uri\": CPU_IMAGE,\n",
        "    \"command\": [],\n",
        "    \"args\": [\n",
        "        '--sleep=600s',\n",
        "    ],\n",
        "  },\n",
        "  \"disk_spec\": DISK_SPEC\n",
        "}\n",
        "\n",
        "print('CPU worker spec:\\n', json.dumps(CPU_WORKER_SPEC, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTUKhLJYozpU"
      },
      "source": [
        "## 3-3. Create CPU test job on Vertex AI Training - us-central1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7VCxyuS7WpZi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling endpoint: https://us-central1-aiplatform.googleapis.com/v1beta1/projects/ds-dev-jb0001/locations/us-central1/customJobs to create custom training job\n",
            "{\n",
            "  \"display_name\": \"CPU Test Job PSC-I\",\n",
            "  \"job_spec\": {\n",
            "    \"worker_pool_specs\": [\n",
            "      {\n",
            "        \"machine_spec\": {\n",
            "          \"machine_type\": \"n2-standard-4\"\n",
            "        },\n",
            "        \"replica_count\": 1,\n",
            "        \"container_spec\": {\n",
            "          \"image_uri\": \"us-docker.pkg.dev/ds-dev-jb0001/vertex-training-test/test:latest\",\n",
            "          \"command\": [],\n",
            "          \"args\": [\n",
            "            \"--sleep=1200s\"\n",
            "          ]\n",
            "        },\n",
            "        \"disk_spec\": {\n",
            "          \"boot_disk_type\": \"pd-ssd\",\n",
            "          \"boot_disk_size_gb\": 100\n",
            "        }\n",
            "      }\n",
            "    ],\n",
            "    \"service_account\": \"277369590897-compute@developer.gserviceaccount.com\",\n",
            "    \"psc_interface_config\": {\n",
            "      \"network_attachment\": \"projects/546029343527/regions/us-central1/networkAttachments/us-central1-vertex-psci\"\n",
            "    },\n",
            "    \"enable_web_access\": true\n",
            "  },\n",
            "  \"labels\": {\n",
            "    \"network_type\": \"psc-i\"\n",
            "  }\n",
            "}\n",
            "response: <Response [200]>\n",
            "Created Job:  projects/277369590897/locations/us-central1/customJobs/6669564914782175232\n",
            "Link: https://console.cloud.google.com/vertex-ai/locations/us-central1/training/6669564914782175232/cpu?&project=ds-dev-jb0001\n"
          ]
        }
      ],
      "source": [
        "# us-central1 job\n",
        "job_name_central, job_id_central, custom_job_response_central = create_single_replica_cpu_job(PROJECT_ID,\n",
        "                                                                      REGION_CENTRAL,\n",
        "                                                                      network_peering=None,\n",
        "                                                                      network_attachment=FULL_NETWORK_ATTACHMENT_NAME_CENTRAL,\n",
        "                                                                      enable_web_access=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cd-gOg_ltBgo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"error\": {\n",
            "    \"code\": 404,\n",
            "    \"message\": \"The Artifact Registry repository projects/ds-dev-jb0001/locations/us-central1/repositories/vertex-training-test does not exist.\",\n",
            "    \"status\": \"NOT_FOUND\",\n",
            "    \"details\": [\n",
            "      {\n",
            "        \"@type\": \"type.googleapis.com/google.rpc.DebugInfo\",\n",
            "        \"detail\": \"[ORIGINAL ERROR] generic::not_found: com.google.cloud.ai.platform.common.errors.AiPlatformException: code=NOT_FOUND, message=The Artifact Registry repository projects/ds-dev-jb0001/locations/us-central1/repositories/vertex-training-test does not exist., cause=null [google.rpc.error_details_ext] { code: 5 message: \\\"The Artifact Registry repository projects/ds-dev-jb0001/locations/us-central1/repositories/vertex-training-test does not exist.\\\" }\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(json.loads(custom_job_response_central.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1ruO-XvDV-Z"
      },
      "source": [
        "## 3-4. Create CPU test job on Vertex AI Training - us-west1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulpukjYl_u4L"
      },
      "outputs": [],
      "source": [
        "# us-west1 job\n",
        "job_name_west, job_id_west, custom_job_response_west = create_single_replica_cpu_job(PROJECT_ID,\n",
        "                                                                      REGION_WEST,\n",
        "                                                                      network_peering=None,\n",
        "                                                                      network_attachment=FULL_NETWORK_ATTACHMENT_NAME_WEST,\n",
        "                                                                      enable_web_access=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWBkzBHT_4j7"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(json.loads(custom_job_response_west.text), indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6sCvRkPX0gf"
      },
      "source": [
        "## 3-5. Monitor and debug training with an interactive shell\n",
        "\n",
        "The jobs in this project have [enabled interactive shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) for the custom training resource. The interactive shell allows you to inspect the container where your training code is running.\n",
        "\n",
        "You can navitage to the interactive shell with [these](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell#navigate-console) instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOyxqfCjj3Vf"
      },
      "source": [
        "# 4-0. Get Job Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQsQHP6sj5VT"
      },
      "outputs": [],
      "source": [
        "# Option 1: Use the Custom Job ID to get details\n",
        "# JOB_ID = \"\" # @param {type:\"string\"}\n",
        "# !gcloud beta ai custom-jobs describe {JOB_ID} --project={PROJECT_ID} --region={REGION}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMxAZU94j-FE"
      },
      "outputs": [],
      "source": [
        "# Option 2: List existing custom jobs, filter running jobs and ones with the set label\n",
        "# Lists the existing custom jobs, filters with the label set for these jobs\n",
        "FILTER = '\"(state!=\"JOB_STATE_SUCCEEDED\" AND state!=\"JOB_STATE_FAILED\" AND state!=\"JOB_STATE_CANCELLED\") AND labels.network_type=psc-i\"'\n",
        "!gcloud beta ai custom-jobs list --project={PROJECT_ID} --region={REGION_CENTRAL} --filter={FILTER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdKGTMmHzxcN"
      },
      "outputs": [],
      "source": [
        "!gcloud beta ai custom-jobs list --project={PROJECT_ID} --region={REGION_WEST} --filter={FILTER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "# 5-0. Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:\n",
        "\n",
        "- Artifacts Repository\n",
        "- VPC Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Set this to true only if you'd like to delete your bucket\n",
        "# delete_bucket = False\n",
        "delete_artifacts_repo = False\n",
        "\n",
        "# No bucket used in this example\n",
        "# if delete_bucket:\n",
        "#   !gsutil rm -rf $JOB_DIR\n",
        "#   !gsutil rm -r $BUCKET_URI\n",
        "\n",
        "if delete_artifacts_repo:\n",
        "  !gcloud artifacts repositories delete {PRIVATE_REPO} --project={PROJECT_ID} --location={REGION} --quiet"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
