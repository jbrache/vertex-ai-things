{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Vertex AI Training/Pipelines PSC Interface Job Submission\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/jbrache/vertex-ai-things/blob/main/codelabs/training-psc-interface-proxy/psc_interface_vertex_ai_job_submission.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fjbrache%2Fvertex-ai-things%2Fmain%2Fcodelabs%2Ftraining-psc-interface-proxy%2Fpsc_interface_vertex_ai_job_submission.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/jbrache/vertex-ai-things/main/codelabs/training-psc-interface-proxy/psc_interface_vertex_ai_job_submission.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/jbrache/vertex-ai-things/blob/main/codelabs/training-psc-interface-proxy/psc_interface_vertex_ai_job_submission.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://storage.googleapis.com/github-repo/generative-ai/logos/GitHub_Invertocat_Dark.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use the Private Service Connect (PSC) Interface resources created from Terraform to submit a Vertex AI Training job and Vertex AI Pipelines Job.\n",
        "\n",
        "The jobs perform a wget from Vertex AI Training to the explicit proxy. This allows you to reach non-RFC 1918 VMs, such as the class-e-vm. An explicit proxy is not required for Vertex AI Pipelines to access rfc1918-vm, as its target is an RFC 1918 IP address.\n",
        "\n",
        "Steps performed in the notebook:\n",
        "* Configure project and resource information\n",
        "* Submit Vertex AI Training Job\n",
        "* Submit Vertex AI Pipelines Job\n",
        "* Validate PSC Interface\n",
        "* Validate Cloud Logging\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
        "                                  google-cloud-storage \\\n",
        "                                  kfp \\\n",
        "                                  google-cloud-pipeline-components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"codelab-dev-jb0005\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "REGION = str(LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaKv5qj9rIXb"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER = !(gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\")\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "PROJECT_NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vklYk_OfHEN"
      },
      "outputs": [],
      "source": [
        "# This bucket is used for Vertex AI Pipeliens\n",
        "BUCKET_NAME = \"codelab-dev-jb0005-aiplatform\" # @param {type: \"string\"}\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "\n",
        "IMAGE_REPO = 'pipelines-test-repo-psc'\n",
        "IMAGE_NAME = 'nonrfc-ip-call'\n",
        "TAG = 'latest'\n",
        "\n",
        "IMAGE_URI= f'us-docker.pkg.dev/{PROJECT_ID}/{IMAGE_REPO}/{IMAGE_NAME}:{TAG}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYda92IyfWj2"
      },
      "outputs": [],
      "source": [
        "# PSC-I configs\n",
        "NETWORK_ATTACHMENT_NAME = \"us-central1-vertex-psci\"\n",
        "NETWORK_ATTACHMENT_ID = f\"projects/{PROJECT_ID}/regions/{REGION}/networkAttachments/{NETWORK_ATTACHMENT_NAME}\"\n",
        "\n",
        "TARGET_PROJECT = str(PROJECT_ID)\n",
        "TARGET_NETWORK = \"consumer-vpc\" #@param {type:\"string\"}\n",
        "DNS_DOMAIN = 'demo.com.' #@param {type:\"string\"}\n",
        "\n",
        "CLASS_E_IP = 'class-e-vm.demo.com' #@param {type:\"string\"}\n",
        "NON_RFC_URL = f\"http://{CLASS_E_IP}\"\n",
        "\n",
        "PROXY_VM_IP = \"proxy-vm.demo.com\" #@param {type:\"string\"}\n",
        "PROXY_VM_PORT = \"8888\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d95621cbf42f"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03d54ffcdeac"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## 1: Submit Vertex AI Training Job (Vertex AI SDK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t--spVL5glkV"
      },
      "outputs": [],
      "source": [
        "JOB_ID_PREFIX='test_psci-nonRFC' #@param {type:\"string\"}\n",
        "JOB_ID = '{}_{}'.format(JOB_ID_PREFIX, datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFGsEAHphshz"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "def create_custom_job_psci_sample(\n",
        "    project: str,\n",
        "    location: str,\n",
        "    bucket: str,\n",
        "    display_name: str,\n",
        "    machine_type: str,\n",
        "    replica_count: int,\n",
        "    image_uri: str,\n",
        "    network_attachment: str,\n",
        "    domain: str,\n",
        "    target_project: str,\n",
        "    target_network: str,\n",
        "):\n",
        "    \"\"\"Custom training job sample with PSC Interface Config.\"\"\"\n",
        "    aiplatform.init(project=project, location=location, staging_bucket=bucket)\n",
        "\n",
        "    worker_pool_specs = [{\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": machine_type,\n",
        "        },\n",
        "        \"replica_count\": replica_count,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": image_uri,\n",
        "            \"command\": [],\n",
        "            \"args\": [\"--sleep=600s\"],\n",
        "            \"env\": [\n",
        "                {\n",
        "                    \"name\": \"NONRFC_URL\",\n",
        "                    \"value\": NON_RFC_URL\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"PROXY_VM_IP\",\n",
        "                    \"value\": PROXY_VM_IP\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"PROXY_VM_PORT\",\n",
        "                    \"value\": PROXY_VM_PORT\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "    }]\n",
        "    psc_interface_config = {\n",
        "        \"network_attachment\": network_attachment,\n",
        "        \"dns_peering_configs\": [\n",
        "            {\n",
        "                \"domain\": domain,\n",
        "                \"target_project\": target_project,\n",
        "                \"target_network\": target_network,\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "    job = aiplatform.CustomJob(\n",
        "        display_name=display_name,\n",
        "        worker_pool_specs=worker_pool_specs,\n",
        "    )\n",
        "\n",
        "    job.run(\n",
        "        psc_interface_config=psc_interface_config,\n",
        "        sync=False,\n",
        "    )\n",
        "\n",
        "    return job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDSekE8TjEO2"
      },
      "outputs": [],
      "source": [
        "job = create_custom_job_psci_sample(\n",
        "    project = PROJECT_ID,\n",
        "    location = LOCATION,\n",
        "    bucket = BUCKET_URI,\n",
        "    display_name = JOB_ID,\n",
        "    machine_type = \"n2-standard-4\",\n",
        "    replica_count = 1,\n",
        "    image_uri = IMAGE_URI,\n",
        "    network_attachment=NETWORK_ATTACHMENT_ID,\n",
        "    domain = DNS_DOMAIN,\n",
        "    target_project = TARGET_PROJECT,\n",
        "    target_network = TARGET_NETWORK\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHOxjCUap0pN"
      },
      "source": [
        "## 2: (Optional) Submit Vertex AI Training Job (REST API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vMv0z2Vq1hP"
      },
      "outputs": [],
      "source": [
        "SERVICE_NAME = \"aiplatform\"\n",
        "SERVICE =f\"{SERVICE_NAME}.googleapis.com\"\n",
        "ENDPOINT=f\"{REGION}-{SERVICE_NAME}.googleapis.com\"\n",
        "API_VERSION = \"v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbwpFPBRqIkz"
      },
      "outputs": [],
      "source": [
        "JOB_ID = f'{JOB_ID_PREFIX}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwH-n8fZpmRK"
      },
      "outputs": [],
      "source": [
        "CUSTOM_JOB = {\n",
        "  \"display_name\": JOB_ID,\n",
        "  \"job_spec\": {\n",
        "      \"worker_pool_specs\": [\n",
        "          {\n",
        "           \"machine_spec\": {\n",
        "             \"machine_type\": \"n2-standard-4\",\n",
        "           },\n",
        "           \"replica_count\": 1,\n",
        "           \"container_spec\": {\n",
        "             \"image_uri\": IMAGE_URI,\n",
        "             \"env\": [{\n",
        "               \"name\": \"NONRFC_URL\",\n",
        "               \"value\": NON_RFC_URL\n",
        "             },\n",
        "             {\n",
        "               \"name\": \"PROXY_VM_IP\",\n",
        "               \"value\": PROXY_VM_IP\n",
        "             },\n",
        "             {\n",
        "               \"name\": \"PROXY_VM_PORT\",\n",
        "               \"value\": PROXY_VM_PORT\n",
        "             }]\n",
        "           },\n",
        "         },\n",
        "      ],\n",
        "      \"enable_web_access\": True,\n",
        "      \"psc_interface_config\": {\n",
        "        \"network_attachment\": NETWORK_ATTACHMENT_ID,\n",
        "        \"dns_peering_configs\": [\n",
        "          {\n",
        "            \"domain\": DNS_DOMAIN,\n",
        "            \"target_project\": PROJECT_ID,\n",
        "            \"target_network\": TARGET_NETWORK\n",
        "          },\n",
        "        ]\n",
        "      },\n",
        "  }\n",
        "}\n",
        "\n",
        "print(json.dumps(CUSTOM_JOB, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3_jHL7lqWgH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "bearer_token = !gcloud auth application-default print-access-token\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer {}'.format(bearer_token[0]),\n",
        "}\n",
        "\n",
        "request_uri = f\"https://{REGION}-aiplatform.googleapis.com/{API_VERSION}/projects/{PROJECT_NUMBER}/locations/{REGION}/customJobs/\"\n",
        "\n",
        "print(\"request_uri: \", request_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfPIpU6DrXuE"
      },
      "outputs": [],
      "source": [
        "response_autopush = requests.post(request_uri, json=CUSTOM_JOB, headers=headers)\n",
        "response = response_autopush\n",
        "print(\"response:\", response)\n",
        "if response.reason == 'OK':\n",
        "  job_name = response.json()['name']\n",
        "  job_id = job_name.split('/')[-1]\n",
        "  print(\"Created Job: \", response.json()['name'])\n",
        "else:\n",
        "  print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evOgdk7ysFUd"
      },
      "source": [
        "## 3: Submit Vertex AI Pipelines Job (Vertex AI SDK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flbsnTDcuN_L"
      },
      "outputs": [],
      "source": [
        "# pipeline parameters\n",
        "CACHE_PIPELINE = False # @param {type: \"string\"}\n",
        "_DEFAULT_IMAGE = IMAGE_URI\n",
        "PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline_root/intro\"\n",
        "PIPELINE_DISPLAY_NAME = \"pipeline-nonRFCIP\" # @param {type: \"string\"}\n",
        "print(f\"{PIPELINE_DISPLAY_NAME.lower()}-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z0ff6pru5bx"
      },
      "outputs": [],
      "source": [
        "from re import S\n",
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.dsl import container_component, ContainerSpec\n",
        "from kfp import compiler\n",
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuhoo4F1u8cW"
      },
      "outputs": [],
      "source": [
        "# ==== Component with env variable ====\n",
        "@container_component\n",
        "def dns_peering_test_op(dns_domain: str, proxy_vm_ip:str, proxy_vm_port:str):\n",
        "    return ContainerSpec(\n",
        "        image=_DEFAULT_IMAGE,\n",
        "        command=[\"bash\", \"-c\"],\n",
        "        args=[\n",
        "            \"\"\"\n",
        "            # These are installed in the container\n",
        "            # apt-get update && apt-get install inetutils-traceroute inetutils-ping netcat-openbsd curl -y\n",
        "\n",
        "            echo \"Local IP(s): $(hostname -I)\"\n",
        "\n",
        "            echo \"Attempting to trace route to %s\"\n",
        "            traceroute -w 1 -m 7 \"%s\"\n",
        "\n",
        "            echo \"Sending curl requests to http://%s via proxy %s:%s and recording trace...\"\n",
        "            if curl -L -v --trace-ascii /dev/stdout -x http://%s:%s \"http://%s\"; then\n",
        "                echo \"Curl request succeeded!\"\n",
        "            else\n",
        "                echo \"Curl request failed!\"\n",
        "                exit 1\n",
        "            fi\n",
        "            \"\"\" % (dns_domain, dns_domain, dns_domain, proxy_vm_ip, proxy_vm_port, proxy_vm_ip, proxy_vm_port, dns_domain)\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# ==== Pipeline ====\n",
        "@dsl.pipeline(\n",
        "    name=\"dns-peering-test-pipeline\",\n",
        "    description=\"Test DNS Peering using env variable\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "def dns_peering_test_pipeline(dns_domain: str, proxy_vm_ip:str, proxy_vm_port:str):\n",
        "    dns_test_task = dns_peering_test_op(dns_domain=dns_domain, proxy_vm_ip=proxy_vm_ip, proxy_vm_port=proxy_vm_port)\n",
        "    dns_test_task.set_caching_options(enable_caching=CACHE_PIPELINE)\n",
        "\n",
        "# ==== Compile pipeline ====\n",
        "if __name__ == \"__main__\":\n",
        "    aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "    compiler.Compiler().compile(\n",
        "        pipeline_func=dns_peering_test_pipeline,\n",
        "        package_path=\"dns_peering_test_pipeline.yaml\",\n",
        "    )\n",
        "    print(\"✅ Pipeline compiled to dns_peering_test_pipeline.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wKWd9fKwxOb"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "with open(\"dns_peering_test_pipeline.yaml\", \"r\") as stream:\n",
        "  try:\n",
        "    pipeline_spec = yaml.safe_load(stream)\n",
        "    print(pipeline_spec)\n",
        "  except yaml.YAMLError as exc:\n",
        "    print(exc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrD3nFnhvpe_"
      },
      "outputs": [],
      "source": [
        "# Import aiplatform and the appropriate API version v1\n",
        "from google.cloud import aiplatform, aiplatform_v1\n",
        "\n",
        "# Initialize the Vertex SDK using PROJECT_ID and LOCATION\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Create the API endpoint\n",
        "client_options = {\n",
        "\"api_endpoint\": f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "}\n",
        "\n",
        "# Initialize the PipelineServiceClient\n",
        "client = aiplatform_v1.PipelineServiceClient(client_options=client_options)\n",
        "\n",
        "PSCI_INTERFACE_CONFIG = {\n",
        "    \"network_attachment\": NETWORK_ATTACHMENT_ID,\n",
        "    \"dns_peering_configs\": [\n",
        "      {\n",
        "        \"domain\": DNS_DOMAIN,\n",
        "        \"target_project\": TARGET_PROJECT,\n",
        "        \"target_network\": TARGET_NETWORK\n",
        "      }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Construct the request\n",
        "request = aiplatform_v1.CreatePipelineJobRequest(\n",
        "    parent=f\"projects/{PROJECT_ID}/locations/{LOCATION}\",\n",
        "    pipeline_job_id = f\"{PIPELINE_DISPLAY_NAME.lower()}-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}\",\n",
        "    pipeline_job=aiplatform_v1.PipelineJob(\n",
        "        display_name=PIPELINE_DISPLAY_NAME,\n",
        "        pipeline_spec=pipeline_spec,\n",
        "        runtime_config=aiplatform_v1.PipelineJob.RuntimeConfig(\n",
        "            gcs_output_directory=BUCKET_URI,\n",
        "            parameter_values = dict(\n",
        "                dns_domain = NON_RFC_URL,\n",
        "                proxy_vm_ip = PROXY_VM_IP,\n",
        "                proxy_vm_port = PROXY_VM_PORT\n",
        "            ),\n",
        "        ),\n",
        "        psc_interface_config=aiplatform_v1.PscInterfaceConfig(\n",
        "            PSCI_INTERFACE_CONFIG\n",
        "        ),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nRmu2ChydLy"
      },
      "outputs": [],
      "source": [
        "# Make the API call\n",
        "response = client.create_pipeline_job(request=request)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbhSFuKq2Nmh"
      },
      "source": [
        "## 4: (Optional) Submit Vertex AI Pipelines Job (REST API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulmYE3F33kzx"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "with open(\"dns_peering_test_pipeline.yaml\", \"r\") as stream:\n",
        "  try:\n",
        "    pipeline_spec = yaml.safe_load(stream)\n",
        "    print(pipeline_spec)\n",
        "  except yaml.YAMLError as exc:\n",
        "    print(exc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1_P_TtI3Qx2"
      },
      "outputs": [],
      "source": [
        "PIPELINE_JOB = {\n",
        "  \"display_name\": PIPELINE_DISPLAY_NAME,\n",
        "  \"pipeline_spec\": pipeline_spec,\n",
        "  \"runtime_config\": {\n",
        "       \"gcs_output_directory\": BUCKET_URI,\n",
        "       \"parameterValues\": {\n",
        "           \"dns_domain\": NON_RFC_URL,\n",
        "           \"proxy_vm_ip\": PROXY_VM_IP,\n",
        "           \"proxy_vm_port\": PROXY_VM_PORT\n",
        "       }\n",
        "   },\n",
        "   \"psc_interface_config\": {\n",
        "      \"network_attachment\": NETWORK_ATTACHMENT_ID,\n",
        "      \"dns_peering_configs\": [\n",
        "      {\n",
        "        \"domain\": DNS_DOMAIN,\n",
        "        \"target_project\": TARGET_PROJECT,\n",
        "        \"target_network\": TARGET_NETWORK\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "\n",
        "print(json.dumps(PIPELINE_JOB, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqM4LBDD4GJh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "bearer_token = !gcloud auth application-default print-access-token\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer {}'.format(bearer_token[0]),\n",
        "}\n",
        "\n",
        "request_uri = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/pipelineJobs?pipelineJobId={PIPELINE_DISPLAY_NAME.lower()}-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}\"\n",
        "\n",
        "print(\"request_uri: \", request_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeURVNqY4GJi"
      },
      "outputs": [],
      "source": [
        "response_autopush = requests.post(request_uri, json=PIPELINE_JOB, headers=headers)\n",
        "response = response_autopush\n",
        "print(\"response:\", response)\n",
        "if response.reason == 'OK':\n",
        "  job_name = response.json()['name']\n",
        "  job_id = job_name.split('/')[-1]\n",
        "  print(\"Created Pipeline: \", response.json()['name'])\n",
        "else:\n",
        "  print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cloud Logging Validation\n",
        "The Vertex AI Pipelines job will take approx 15 minutes to run the first time, subsequent runs are much shorter. To validate a successful outcome perform the following:\n",
        "\n",
        "Navigate to Vertex AI → Training → Custom jobs - [Cloud Console Link](https://console.cloud.google.com/vertex-ai/training/custom-jobs)\n",
        "\n",
        "Select the executed custom job\n",
        "\n",
        "![Figure 5](resources/images/figure-5-custom-job.png)\n",
        "\n",
        "Select View Logs\n",
        "\n",
        "![Figure 6](resources/images/figure-6-view-job.png)\n",
        "\n",
        "Once Cloud Logging is available, select Run Query that generates the highlighted selection below that confirms a successful wget from Vertex AI Pipelines to the class-e-vm.\n",
        "\n",
        "![Figure 7](resources/images/figure-7-logs-explorer.png)\n",
        "\n",
        "![Figure 8](resources/images/figure-8-job-logging.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Enable TCPDump\n",
        "To validate IP connectivity from Vertex AI Pipelines, we can use TCPDUMP. This will allow us to observe communication originating from the PSC Network Attachment subnet, 192.168.10.0/28 when invoking the get request from Vertex AI Pipelines to the vm, class-e-vm.demo.com (240.0.0.0/4).\n",
        "\n",
        " From Cloud Shell ssh into the proxy vm.\n",
        "\n",
        "```\n",
        "gcloud compute ssh --zone us-central1-a \"proxy-vm\" --tunnel-through-iap --project $PROJECT_ID\n",
        "```\n",
        "\n",
        " From the proxy-vm OS execute tcpdump filtering on the class-e-vm and PSC network attachment subnet.\n",
        "\n",
        "```\n",
        "sudo tcpdump -i any net 240.0.0.0/4 or 192.168.10.0/28 -nn\n",
        "```\n",
        "\n",
        "Open a new Cloud Shell tab, update your project variable and ssh into the class-e-vm\n",
        "\n",
        "```\n",
        "gcloud compute ssh --zone us-central1-a \"class-e-vm\" --tunnel-through-iap --project $PROJECT_ID\n",
        "```\n",
        "\n",
        " From the class-e-vm OS execute tcpdump filtering on the proxy-vm subnet..\n",
        "\n",
        "```\n",
        "sudo tcpdump -i any net 10.10.10.0/28 -nn\n",
        "```\n",
        "\n",
        "### 6.1 TCPDump Validation\n",
        "Let's review the TCPDUMP output that further validates the connectivity to compute instances:\n",
        "\n",
        "From proxy-vm observe the HTTP GET and 200 OK\n",
        "\n",
        "```console\n",
        "03:05:34.778574 ens4  Out IP 10.10.10.2.40326 > 240.0.0.2.80: Flags [P.], seq 1:63, ack 1, win 511, options [nop,nop,TS val 1435446009 ecr 2475360885], length 62: HTTP: GET / HTTP/1.0\n",
        "03:05:34.778946 ens4  In  IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [.], ack 63, win 506, options [nop,nop,TS val 2475360889 ecr 1435446009], length 0\n",
        "03:05:34.778974 ens4  Out IP 10.10.10.2.40326 > 240.0.0.2.80: Flags [P.], seq 63:185, ack 1, win 511, options [nop,nop,TS val 1435446010 ecr 2475360889], length 122: HTTP\n",
        "03:05:34.781999 ens4  In  IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [.], ack 185, win 506, options [nop,nop,TS val 2475360892 ecr 1435446010], length 0\n",
        "03:05:34.906678 ens4  In  IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [P.], seq 1:265, ack 185, win 506, options [nop,nop,TS val 2475361016 ecr 1435446010], length 264: HTTP: HTTP/1.1 200 OK\n",
        "```\n",
        "\n",
        "From class-e-vm observe the HTTP GET and 200 OK\n",
        "\n",
        "```console\n",
        "03:05:34.778768 ens4  In  IP 10.10.10.2.40326 > 240.0.0.2.80: Flags [P.], seq 1:63, ack 1, win 511, options [nop,nop,TS val 1435446009 ecr 2475360885], length 62: HTTP: GET / HTTP/1.0\n",
        "03:05:34.778819 ens4  Out IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [.], ack 63, win 506, options [nop,nop,TS val 2475360889 ecr 1435446009], length 0\n",
        "03:05:34.781815 ens4  In  IP 10.10.10.2.40326 > 240.0.0.2.80: Flags [P.], seq 63:185, ack 1, win 511, options [nop,nop,TS val 1435446010 ecr 2475360889], length 122: HTTP\n",
        "03:05:34.781856 ens4  Out IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [.], ack 185, win 506, options [nop,nop,TS val 2475360892 ecr 1435446010], length 0\n",
        "03:05:34.906503 ens4  Out IP 240.0.0.2.80 > 10.10.10.2.40326: Flags [P.], seq 1:265, ack 185, win 506, options [nop,nop,TS val 2475361016 ecr 1435446010], length 264: HTTP: HTTP/1.1 200 OK\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4e033321ad"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "Vertex AI Training and Vertex AI Pipelines were created in this notebook. To clean up resources, follow steps in the README.md in this directory."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
